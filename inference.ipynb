{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30997120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "from ASTE_dataloader import load_vocab\n",
    "from scheme.span_tagging import form_label_id_map, form_sentiment_id_map\n",
    "from model import base_model\n",
    "\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b583e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = 'data\\ASTE-Data-V2-EMNLP2020'\n",
    "dataset_dir = 'data\\ASTE-Data-V2-EMNLP2020_TRANSLATED_TO_ARABIC'\n",
    "dataset = '16res'\n",
    "version = '3D'\n",
    "bert_model= 'aubmindlab/bert-base-arabertv2'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "modelPath = 'outputs\\\\best_models\\\\16res_3D_True_best.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "277b3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "dataset_dir = dataset_dir + '/' + dataset\n",
    "vocab = load_vocab(dataset_dir = dataset_dir)\n",
    "label2id, id2label = form_label_id_map(version)\n",
    "senti2id, id2senti = form_sentiment_id_map()\n",
    "vocab['label_vocab'] = dict(label2id=label2id,id2label=id2label)\n",
    "vocab['senti_vocab'] = dict(senti2id=senti2id,id2senti=id2senti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488cc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, tokenizer, vocab, max_len=128, lower=True):\n",
    "    \"\"\"\n",
    "    Preprocess a single sentence for inference with the STAGE model.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): Input sentence as a string\n",
    "        tokenizer: BERT tokenizer\n",
    "        vocab: Vocabulary dictionary containing token_vocab and label mappings\n",
    "        version (str): Tagging scheme version ('3D', '2D', or '1D')\n",
    "        max_len (int): Maximum length for BERT tokens\n",
    "        lower (bool): Whether to lowercase the text\n",
    "        \n",
    "    Returns:\n",
    "        dict: Preprocessed input ready for model inference\n",
    "    \"\"\"\n",
    "    # Split sentence into tokens\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # Extract required vocabularies\n",
    "    token_vocab = vocab['token_vocab']\n",
    "    \n",
    "    # Get special token IDs\n",
    "    CLS_id = tokenizer.convert_tokens_to_ids([tokenizer.cls_token])\n",
    "    SEP_id = tokenizer.convert_tokens_to_ids([tokenizer.sep_token])\n",
    "    \n",
    "    # Lowercase if needed\n",
    "    if lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "    \n",
    "    # Convert to BERT tokens and get word mapping\n",
    "    def text2bert_id(tokens):\n",
    "        re_token = []\n",
    "        word_mapback = []\n",
    "        word_split_len = []\n",
    "        for idx, word in enumerate(tokens):\n",
    "            temp = tokenizer.tokenize(word)\n",
    "            re_token.extend(temp)\n",
    "            word_mapback.extend([idx] * len(temp))\n",
    "            word_split_len.append(len(temp))\n",
    "        re_id = tokenizer.convert_tokens_to_ids(re_token)\n",
    "        return re_id, word_mapback, word_split_len\n",
    "    \n",
    "    # Process tokens to BERT IDs\n",
    "    text_raw_bert_indices, word_mapback, _ = text2bert_id(tokens)\n",
    "    \n",
    "    # Truncate to max length\n",
    "    text_raw_bert_indices = text_raw_bert_indices[:max_len]\n",
    "    word_mapback = word_mapback[:max_len]\n",
    "    \n",
    "    # Get token length and check\n",
    "    length = word_mapback[-1] + 1 if word_mapback else 0\n",
    "    if length != len(tokens):\n",
    "        # Truncate tokens if needed\n",
    "        tokens = tokens[:length]\n",
    "    \n",
    "    bert_length = len(word_mapback)\n",
    "    \n",
    "    # Convert tokens to IDs\n",
    "    token_ids = [token_vocab.stoi.get(t, token_vocab.unk_index) for t in tokens[:length]]\n",
    "    \n",
    "    # Create processed dictionary\n",
    "    processed = {\n",
    "        'token': token_ids,\n",
    "        'token_length': length,\n",
    "        'bert_token': CLS_id + text_raw_bert_indices + SEP_id,\n",
    "        'bert_length': bert_length,\n",
    "        'bert_word_mapback': word_mapback,\n",
    "        'golden_label': None  # No labels for inference\n",
    "    }\n",
    "    \n",
    "    # Convert to batch format (single item batch)\n",
    "    batch = {\n",
    "        'token': torch.LongTensor([processed['token']]),\n",
    "        'token_length': torch.tensor([processed['token_length']]),\n",
    "        'bert_token': torch.LongTensor([processed['bert_token']]),\n",
    "        'bert_length': torch.tensor([processed['bert_length']]),\n",
    "        'bert_word_mapback': torch.LongTensor([processed['bert_word_mapback']]),\n",
    "        'golden_label': None\n",
    "    }\n",
    "    \n",
    "    return batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723ae0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets_from_output(outputs, tokens, id2label, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Extract aspect-sentiment-opinion triplets from model outputs\n",
    "    \n",
    "    Args:\n",
    "        outputs: Model output logits\n",
    "        tokens: Original sentence tokens\n",
    "        id2label: Mapping from ID to label string\n",
    "        threshold: Confidence threshold for predictions\n",
    "        \n",
    "    Returns:\n",
    "        list: Extracted triplets in [(aspect, opinion, sentiment)] format\n",
    "    \"\"\"\n",
    "    # Get the predicted labels for each span\n",
    "    raw_predicted_table_id = outputs['logits'].argmax(dim=-1).cpu().numpy()[0]\n",
    "    scores = torch.softmax(outputs['logits'], dim=-1).cpu().numpy()[0]\n",
    "    \n",
    "    # Map IDs back to label strings\n",
    "    predicted_table = [[id2label[x] for x in y] for y in raw_predicted_table_id]\n",
    "    \n",
    "    # Extract spans based on the tagging scheme\n",
    "    aspect_spans = []\n",
    "    opinion_spans = []\n",
    "    sentiment_spans = {}\n",
    "    \n",
    "    n = len(tokens)\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            confidence = scores[i, j, raw_predicted_table_id[i, j]]\n",
    "            if confidence < threshold:\n",
    "                continue\n",
    "                \n",
    "            label = predicted_table[i][j]\n",
    "            \n",
    "            # Parse based on tagging scheme (3D/2D/1D)\n",
    "            if '-' in label:  # 3D or 2D\n",
    "                parts = label.split('-')\n",
    "                if len(parts) == 3:  # 3D scheme\n",
    "                    aspect_part, opinion_part, sentiment_part = parts\n",
    "                    if aspect_part == 'A':\n",
    "                        aspect_spans.append((i, j))\n",
    "                    if opinion_part == 'O':\n",
    "                        opinion_spans.append((i, j))\n",
    "                    if sentiment_part not in ['N', '']:\n",
    "                        sentiment_spans[(i, j)] = sentiment_part\n",
    "                elif len(parts) == 2:  # 2D scheme\n",
    "                    aspect_opinion_part, sentiment_part = parts\n",
    "                    if aspect_opinion_part == 'A':\n",
    "                        aspect_spans.append((i, j))\n",
    "                    elif aspect_opinion_part == 'O':\n",
    "                        opinion_spans.append((i, j))\n",
    "                    if sentiment_part not in ['N', '']:\n",
    "                        sentiment_spans[(i, j)] = sentiment_part\n",
    "            else:  # 1D scheme\n",
    "                if label == 'A':\n",
    "                    aspect_spans.append((i, j))\n",
    "                elif label == 'O':\n",
    "                    opinion_spans.append((i, j))\n",
    "                elif label in ['POS', 'NEG', 'NEU']:\n",
    "                    sentiment_spans[(i, j)] = label\n",
    "    \n",
    "    # Extract triplets using greedy inference\n",
    "    triplets = []\n",
    "    for a_span in aspect_spans:\n",
    "        for o_span in opinion_spans:\n",
    "            # Check if a valid sentiment exists\n",
    "            sentiment = None\n",
    "            \n",
    "            # Case 1: sentiment for the combined span\n",
    "            combined_span = (min(a_span[0], o_span[0]), max(a_span[1], o_span[1]))\n",
    "            if combined_span in sentiment_spans:\n",
    "                sentiment = sentiment_spans[combined_span]\n",
    "            \n",
    "            # Case 2: sentiment for aspect span\n",
    "            elif a_span in sentiment_spans:\n",
    "                sentiment = sentiment_spans[a_span]\n",
    "            \n",
    "            # Case 3: sentiment for opinion span\n",
    "            elif o_span in sentiment_spans:\n",
    "                sentiment = sentiment_spans[o_span]\n",
    "            \n",
    "            if sentiment:\n",
    "                aspect_text = \" \".join(tokens[a_span[0]:a_span[1]+1])\n",
    "                opinion_text = \" \".join(tokens[o_span[0]:o_span[1]+1])\n",
    "                triplets.append((aspect_text, opinion_text, sentiment))\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7035c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(model, sentence, device):\n",
    "    \"\"\"\n",
    "    Get model outputs for a given batch\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        batch: Preprocessed input batch\n",
    "        device: Device to run the model on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Model outputs including logits and other information\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    input_batch = preprocess_sentence(\n",
    "        sentence=sentence,\n",
    "        tokenizer=tokenizer,\n",
    "        vocab=vocab,\n",
    "    )\n",
    "    \n",
    "    for k in input_batch:\n",
    "        if isinstance(input_batch[k], torch.Tensor):\n",
    "            input_batch[k] = input_batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_batch)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b16c6f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "#load the pickeled model \n",
    "model = torch.load(modelPath, weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.0496 seconds\n",
      "Input: كان النادل في المطعم غير منظم لكن الطعام لذيذ\n",
      "Extracted triplets:\n",
      "  • Aspect: 'النادل', Opinion: 'غير منظم', Sentiment: NEG\n",
      "  • Aspect: 'الطعام', Opinion: 'لذيذ', Sentiment: POS\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "sentence = \"كان النادل في المطعم غير منظم لكن الطعام لذيذ\"\n",
    "start_time = time.time()\n",
    "tokens = sentence.split()\n",
    "outputs = get_outputs(model, sentence, device)\n",
    "# Extract triplets\n",
    "triplets = extract_triplets_from_output(\n",
    "    outputs=outputs,\n",
    "    tokens=tokens,\n",
    "    id2label=vocab['label_vocab']['id2label'],\n",
    "    threshold=0.5  \n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Inference time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Display the extracted triplets\n",
    "print(f\"Input: {sentence}\")\n",
    "print(\"Extracted triplets:\")\n",
    "for aspect, opinion, sentiment in triplets:\n",
    "    print(f\"  • Aspect: '{aspect}', Opinion: '{opinion}', Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31390f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
